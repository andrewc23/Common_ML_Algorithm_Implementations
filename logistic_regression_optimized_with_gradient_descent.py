# -*- coding: utf-8 -*-
"""Logistic_Regression_Optimized_With_Gradient_Descent.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W1Mr-ovgq9Ln4zpy3hWBHbKS8JyEFUUM

##Andrew Clark
##Implementation of Logistic Regression Optimized Via Gradient Descent

Logistic Regression Trained on MNIST Dataset
"""

#load in the data. can also just load in MNIST from sklearn instead if you wish.
data=np.load('data.npy')
labels=np.load('label.npy')

print(data.shape)
print(labels.shape)

#visualize image of a 0
image=data[0]
#image.shape
reshaped=np.reshape(image,(28,28))
plt.imshow(reshaped)

#visualize image of a 1
image=data[14779]
#image.shape
reshaped=np.reshape(image,(28,28))
plt.imshow(reshaped)

#normalize the data to between 0 and 255
normed_data=(1/255)*data

#set the labels to be -1 and 1 using vectorization
labels_almost_done=np.where(labels==0,labels,-2+labels)
labels_done=np.where(labels_almost_done==-1,labels_almost_done,1+labels_almost_done)

#define two functions needed for gradient descent 

def compute_loss(data,labels,B,B_0):
  loss_term_1=B_0+np.matmul(B,data.T)
  loss_term_2=np.multiply((-labels).T,loss_term_1)
  loss_exp_logged=np.log((1+np.exp(loss_term_2)))
  print('dims',loss_exp_logged.shape)
  logloss=loss_exp_logged.mean()
  return logloss

def compute_gradients(data,labels,B,B_0):
  #compute dB
  term_1=np.matmul(B,data.T)
  term_2=B_0+term_1
  term_3=np.multiply((-labels).T,term_2)
  exp_term=np.exp(term_3)
  term_4=(-exp_term/(1+exp_term))
  term_5=np.multiply(term_4,labels.T)
  term_6=np.multiply(term_5.T,data)
  dB=term_6.mean(axis=0)
  #compute dB_0
  dB_0_term_1=np.multiply(term_4,labels)
  dB_0=-dB_0_term_1.mean()
  return dB,dB_0

#test out things
# loss_term_1=B_0+np.matmul(B,train_data.T)
# loss_term_2=np.multiply((-train_labels).T,loss_term_1)
# loss_exp_logged=np.log((1+np.exp(loss_term_2)))
# logloss=loss_exp_logged.mean()

# print(logloss)
# #print(B_0.shape)

#split the data randomly into 80% training and 20% testing

random_indices=np.random.permutation(normed_data.shape[0])
training_indices,testing_indices = random_indices[:11824],random_indices[11824:]
train_data, test_data=normed_data[training_indices],normed_data[testing_indices]
train_labels,test_labels=labels_done[training_indices],labels_done[testing_indices]

#initialize the weights and bias
B=np.random.randn(1,train_data.shape[1])
B_0=np.random.rand(1)

#define learning rate
lr=0.05

#run gradient descent algorithm

acc_test_list=[]
loss_test_list=[]
train_loss_list=[]

for _ in range(50):
  loss=compute_loss(train_data,train_labels,B,B_0)
  train_loss_list.append(loss)
  dB,dB_0=compute_gradients(train_data,train_labels,B,B_0)
  #print(dB.shape)
  #print(dB_0.shape)
  B=B-lr*dB 
  #B_0=B_0-lr*dB_0

  #compute accuracy and loss on the test set.
  #implement accuracy metric
  test_signs=np.sign(B_0+np.matmul(B,test_data.T))
  accuracy_test=np.sum(np.equal(test_signs,test_labels))/(test_data.shape[0])
  acc_test_list.append(100*accuracy_test)
  loss_test=compute_loss(test_data,test_labels,B,B_0)
  loss_test_list.append(loss_test)

#create training loss plot
plt.plot(train_loss_list)
plt.title('Training Loss v. Epoch #')
plt.xlabel('Epoch #')
plt.ylabel('Training Loss')

#create testing loss plot
plt.plot(loss_test_list)
plt.title('Test Set Loss v. Epoch #')
plt.xlabel('Epoch #')
plt.ylabel('Test Set Loss')

#plot testing accuracy
plt.plot(acc_test_list)
plt.xlabel('Epoch #')
plt.ylabel('Test Set Accuracy')
plt.title('Test Set Accuracy v. Epoch #')

print('Train Loss After 50 Epochs: ', train_loss_list[-1])
print('Test Loss After 50 Epochs: ',loss_test_list[-1])

"""Training loss after 50 epochs = 0.32098. Test set loss after 50 epochs = 0.34664."""

print('Test Set Accuracy after 50 Epochs: ', acc_test_list[-1],'%')

"""The test set accuracy after 50 epochs is equal to 90.05%."""